# adversarial-playground
This repo reproduces several popular adversarial attacks and defenses, applying such methods to different datasets and applications. The objectives of this project are threefold:

- Give a glimpse at the current state of the art when it comes to adversarial machine learning
- See if there are any underlying trends among datasets/types of machine learning models that make them more vulnerable to adversarial examples
- Make it easier to reproduce popular adversarial attacks and defenses, applying them to a wider set of application fieldss
